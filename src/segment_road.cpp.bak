#include <ros/ros.h>
#include <iostream>
#include <inference_engine.hpp>
#include <sensor_msgs/Image.h>
#include <opencv2/opencv.hpp>
#include <sensor_msgs/Image.h>

using namespace InferenceEngine;

//Frames for keeping received images
cv::Mat frame_now;
cv::Mat frame_next;

//Node parameters
std::string device;
float confidence_thresh;
std::string network_loc;
std::string weights_loc;

//For loading plugin for specified device
InferencePlugin device_plugin;

//For loading network to device
ExecutableNetwork model_network;

//For storing network info
std::string inputLayerName;
std::string outputLayerName;


//For storing inference request object
InferRequest::Ptr inferReqCurr;
InferRequest::Ptr inferReqNext;

//For fetching results
float *output_data;
Blob::Ptr output_blob;


//output msg classes
sensor_msgs::Image output_image_msg;

//Flags
bool frame_available=false;
bool last_frame=true;



//OpenCV mat to blob
static InferenceEngine::Blob::Ptr mat_to_blob(const cv::Mat &image) {
    InferenceEngine::TensorDesc tensor(InferenceEngine::Precision::U8,{1, (size_t)image.channels(), (size_t)image.size().height, (size_t)image.size().width},InferenceEngine::Layout::NHWC);
    return InferenceEngine::make_shared_blob<uint8_t>(tensor, image.data);
}

//Image to blob
void frame_to_blob(const cv::Mat& image, InferRequest::Ptr& inferReq, const std::string& descriptor) {
    inferReq->SetBlob(descriptor, mat_to_blob(image));
}

//To run each time a new image is obtained
void imageCallback(const sensor_msgs::Image::ConstPtr& image_msg){
    cv::Mat color_mat(image_msg->height,image_msg->width,CV_MAKETYPE(CV_8U,3),const_cast<uchar*>(&image_msg->data[0]), image_msg->step);
    cv::cvtColor(color_mat,color_mat,cv::COLOR_BGR2RGB);
    std::cout<<"Callback ran!\n";
    if(!frame_available){
        color_mat.copyTo(frame_now);
        frame_available=true;
    }
    color_mat.copyTo(frame_next);
    last_frame=false;
}

int main(int argc, char **argv) {
	ros::init(argc, argv, "segment_road");
	ros::NodeHandle nh;
	ros::Subscriber image_sub = nh.subscribe("/segment_road/inp_img",1,imageCallback);
	ros::Publisher bg_results = nh.advertise<sensor_msgs::Image>("/segment_road/background",1);
	ros::Publisher road_results = nh.advertise<sensor_msgs::Image>("/segment_road/road",1);
	ros::Publisher curb_results = nh.advertise<sensor_msgs::Image>("/segment_road/curb",1);
	ros::Publisher marks_results = nh.advertise<sensor_msgs::Image>("/segment_road/marks",1);

	//Fetch parameters
	try{
		if(!nh.getParam("/segment_road/threshold", confidence_thresh)){
			confidence_thresh=0.5;
		}
		if(!nh.getParam("/segment_road/target", device)){
			device="MYRIAD";
		}
		if(!nh.getParam("/segment_road/network", network_loc)){
			network_loc = "/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/road-segmentation-adas-0001/FP16/road-segmentation-adas-0001.xml";
		}
	
		if(!nh.getParam("/segment_road/weights", weights_loc)){
			weights_loc = "/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/road-segmentation-adas-0001/FP16/road-segmentation-adas-0001.bin";
		}
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error fetching parameters. More:" << e.what() << std::endl;
		return -1;
	}

	try{
		//Loading plugin as per the specified device
		device_plugin = PluginDispatcher({"../../../lib/intel64", ""}).getPluginByDevice(device);
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error fetching plugin for specified device. More:" << e.what() << std::endl;
		return -1;
	}

	//Reading netowrk from IR
	CNNNetReader network_reader;
	try{
		network_reader.ReadNetwork(network_loc);
		network_reader.ReadWeights(weights_loc);
     	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error reading network from IR. More:" << e.what() << std::endl;
		return -1;
	}
	try{
		//input setup
		InputsDataMap input_info(network_reader.getNetwork().getInputsInfo());
       
		InputInfo::Ptr& input_data = input_info.begin()->second;
		inputLayerName = input_info.begin()->first;
		input_data->setPrecision(Precision::U8);
	
		input_data->getPreProcess().setResizeAlgorithm(ResizeAlgorithm::RESIZE_BILINEAR);
		input_data->getInputData()->setLayout(Layout::NHWC);
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error loading/configuring input layer. More:" << e.what() << std::endl;
		return -1;
	}
	try{
		//output setup
		OutputsDataMap output_info(network_reader.getNetwork().getOutputsInfo());
		DataPtr& output_dat = output_info.begin()->second;
		outputLayerName = output_info.begin()->first;
		
		output_dat->setPrecision(Precision::FP32);
		output_dat->setLayout(Layout::NCHW);
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error loading/configuring output layer. More:" << e.what() << std::endl;
		return -1;
	}
	try{
		//Loading network to device
		model_network = device_plugin.LoadNetwork(network_reader.getNetwork(), {});
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error loading network to device. More:" << e.what() << std::endl;
		return -1;
	}	
	try{
		//Create inference request objects for handling current and upcoming frame
		inferReqNext = model_network.CreateInferRequestPtr();
        	inferReqCurr = model_network.CreateInferRequestPtr();
	}
	catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error creating inference request objects. More:" << e.what() << std::endl;
		return -1;
	}
	bool first_frame = true;

	//loop while roscore running
	while(ros::ok()){
		try{
			//Run all callbacks
			ros::spinOnce();
		}
		catch(const std::exception& e){
		ROS_ERROR("%s",e.what());
		std::cout<<"Error calling callbacks to check topic. More:" << e.what() << std::endl;
		return -1;
		}
		if(frame_available){
			try{
				//Associate the frame to its inference request
				if(first_frame){
					frame_to_blob(frame_now, inferReqCurr, inputLayerName);
				}
				if(!last_frame){
					frame_to_blob(frame_next, inferReqNext, inputLayerName);
				}
			}
			catch(const std::exception& e){
				ROS_ERROR("%s",e.what());
				std::cout<<"Error associating image blob with inference request. More:" << e.what() << std::endl;
				return -1;
			}
			try{
				//Start the inference requests in Asynchronous mode			        
				if(first_frame){
					std::cout<<"sending inference request\n";
					inferReqCurr->StartAsync();
				}
				if(!last_frame){
					std::cout<<"sending inference request\n";
					inferReqNext->StartAsync();
				}
			}
			catch(const std::exception& e){
				ROS_ERROR("%s",e.what());
				std::cout<<"Error sending Asynchronous inference request. More:" << e.what() << std::endl;
				return -1;
			}
			//Wait for inference result
			if (OK == inferReqCurr->Wait(IInferRequest::WaitMode::RESULT_READY)) {
				std::cout<<"Inference Completed!\n";
				try{
					//Fetch the result associated with the inference request
					output_blob = inferReqCurr->GetBlob(outputLayerName);
					output_data = output_blob->buffer().as<float*>();
				}
				catch(const std::exception& e){
					ROS_ERROR("%s",e.what());
					std::cout<<"Error retrieving inference results. More:" << e.what() << std::endl;
					return -1;
				}
				size_t N = output_blob->getTensorDesc().getDims().at(0); 
       	 			size_t C, H, W;

			        size_t output_blob_shape_size = output_blob->getTensorDesc().getDims().size();

				try{
				        if (output_blob_shape_size == 3) {
						C = 1;
						H = output_blob->getTensorDesc().getDims().at(1);
						W = output_blob->getTensorDesc().getDims().at(2);
				        } else if (output_blob_shape_size == 4) {
						C = output_blob->getTensorDesc().getDims().at(1);
	            				H = output_blob->getTensorDesc().getDims().at(2);
	            				W = output_blob->getTensorDesc().getDims().at(3);
				        } else {
			            		throw std::logic_error("Unexpected output blob shape. Only 4D and 3D output blobs are supported.");
				        }
				}
				catch(const std::exception& e){
					ROS_ERROR("%s",e.what());
					std::cout<<"Error retrieving result matrix size. More:" << e.what() << std::endl;
					return -1;
				}

			        size_t image_stride = W*H*C;
				
				// Iterating over all images
				for (size_t image = 0; image < N; ++image) {
					// This vector stores pixels classes 
					std::vector<std::vector<int>> outArrayClasses(H, std::vector<int>(W, 0));
					std::vector<std::vector<float>> outArrayProb(H, std::vector<float>(W, 0.));
					// Iterating over each pixel	
					for (size_t w = 0; w < W; ++w) {
						for (size_t h = 0; h < H; ++h) {
							// number of channels = 1 means that the output is already ArgMax'ed
							if (C == 1) {
								outArrayClasses[h][w] = static_cast<int>(output_data[image_stride * image + W * h + w]);
							} else {
								// Iterating over each class probability 
								for (int ch = 0; ch < C; ++ch) {
									auto data = output_data[image_stride * image + W * H * ch + W * h + w];
									if (data > outArrayProb[h][w]) {
										outArrayClasses[h][w] = 62*ch;   //*62 for making the values 0,1,2,3 large enough to be visible in image pixel
										outArrayProb[h][w] = (int) 255*data;  //*255 for making prob value large enough to be visible in image pixel
									}
								}
							}
						}
					}
					
					//Publish based on whether model output is one channel or multi channel
					if (C==1){
						//Convert image vector to opencv matrix and publish to background background topic.
						int rows = static_cast<int>(outArrayClasses.size());
						int cols = static_cast<int>(outArrayClasses[0].size());

						cv::Mat output_image(rows, cols, CV_8UC1);
						for (int i = 0; i < rows; i++){
							output_image.row(i) = cv::Mat(outArrayClasses[i]).t();
						}

						output_image_msg.header.stamp=ros::Time::now();
						output_image_msg.header.frame_id= "segmented_result";
						output_image_msg.height=output_image.rows;
						output_image_msg.width=output_image.cols;	
						output_image_msg.encoding="mono8";
						output_image_msg.is_bigendian=false;
						output_image_msg.step=output_image.cols;//*3;
						size_t size = output_image_msg.step * output_image.rows;
						output_image_msg.data.resize(size);
						memcpy((char*)(&output_image_msg.data[0]), output_image.data, size);
						bg_results.publish(output_image_msg);
					} else {
						//Convert image vector of each channel (class) to opencv matrix and publish to background, road, curb, marks topics respectively
						for (size_t ch = 0; ch < C; ++ch) {
							int rows = static_cast<int>(outArrayProb.size());
							int cols = static_cast<int>(outArrayProb[0].size());
	
							cv::Mat output_image(rows, cols, CV_8UC1);
							for (int i = 0; i < rows; i++){
								output_image.row(i) = cv::Mat(outArrayProb[i]).t();
							}
							
							output_image_msg.header.stamp=ros::Time::now();
							output_image_msg.header.frame_id= (ch==0)?"bg":(ch==1)?"road":(ch==2)?"curb":"marks";
							output_image_msg.height=output_image.rows;
							output_image_msg.width=output_image.cols;	
							output_image_msg.encoding="mono8";
							output_image_msg.is_bigendian=false;
							output_image_msg.step=output_image.cols;//*3;
							size_t size = output_image_msg.step * output_image.rows;
							output_image_msg.data.resize(size);
							memcpy((char*)(&output_image_msg.data[0]), output_image.data, size);
	
							//Publish to corresponding topic
							if(ch==0){
								bg_results.publish(output_image_msg);
							} else if (ch==1){
								road_results.publish(output_image_msg);
							} else if (ch==2){
								curb_results.publish(output_image_msg);
							} else {
								marks_results.publish(output_image_msg);
							}
	        				}        		
					}			
				}
			}
		    
			//Spinning again
			ros::spinOnce();
			if (first_frame) {
				first_frame = false;
			}
			frame_now = frame_next;
			frame_next = cv::Mat();
			inferReqCurr.swap(inferReqNext);
			frame_available=false;	
			last_frame=true;
		}
	}
	return 0;
}
